{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCN-approach.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "S4ycn3DlxtEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fully convolutional network for hair segmentation"
      ]
    },
    {
      "metadata": {
        "id": "eCzikjccyQyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "who2zG6byWP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connect with Google drive "
      ]
    },
    {
      "metadata": {
        "id": "aaiKu5BJyUkV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/bdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DntYlzVy7-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Go to the project directory"
      ]
    },
    {
      "metadata": {
        "id": "FvACw0WnzHVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f5649541-662d-494a-d044-5f9b9979dcbb"
      },
      "cell_type": "code",
      "source": [
        "%cd ./../bdrive/My Drive/app/Hair-segmentation\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bdrive/My Drive/app/Hair-segmentation\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  FCN-approach.ipynb  \u001b[01;34mimages\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x-o-_Dm_zGz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Confirm that PIL works"
      ]
    },
    {
      "metadata": {
        "id": "1N_btN98ze8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open(open(\"images/works.jpg\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7EjeamoqIUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If PIL didn't work, run this cell\n",
        "! which pillow\n",
        "! pip uninstall pillow\n",
        "! which pip\n",
        "! /usr/local/bin/pip uninstall pip\n",
        "! apt-get update\n",
        "! apt-get install python3-pip\n",
        "! pip3 install --upgrade pip\n",
        "! pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Eo5Jh8Y1QK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install packages"
      ]
    },
    {
      "metadata": {
        "id": "pYJ6t8sZ1WKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpsFeY_Zxfgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports "
      ]
    },
    {
      "metadata": {
        "id": "vzEY6B3Yx-nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline \n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from torchvision import models, datasets, transforms\n",
        "from torchvision.models.vgg import VGG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAHISzlp1yCc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "oy-PI7yj10Kf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pu245-CR110M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "bdG5eGYg-rXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoder "
      ]
    },
    {
      "metadata": {
        "id": "lyCvyCHh3Xk9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VGG16(VGG):\n",
        "  \n",
        "  def __init__(self, cfg, ranges, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "    super().__init__(self.make_layers(cfg[model]))\n",
        "    \n",
        "    self.ranges = ranges[model]\n",
        "        \n",
        "    if pretrained:\n",
        "      exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "    if not requires_grad:\n",
        "      for parameter in super().parameters():\n",
        "        parameter.requires_grad = False\n",
        "    if remove_fc: \n",
        "      del self.classifier\n",
        "    if show_params:\n",
        "      for name, parameter in self.named_parameters():\n",
        "        print(name, parameter.size())\n",
        "        \n",
        "  def forward(self, x):\n",
        "    output = {}\n",
        "    \n",
        "    # Get the output of each maxpooling layer (There are 5 in VGG) to create skip connections.\n",
        "    for idx in range(len(self.ranges)):\n",
        "      for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "        x = self.features[layer](x)\n",
        "      output[\"pool%d\"%(idx+1)] = x\n",
        "    \n",
        "    return output \n",
        "  \n",
        "  def make_layers(self, cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "      if v == 'M':\n",
        "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "      else:\n",
        "        conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "        if batch_norm:\n",
        "          layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "        else:\n",
        "          layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "        in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7EWU_YD-nKv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decoder "
      ]
    },
    {
      "metadata": {
        "id": "huxW8v5B15NR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FCN8s(nn.Module):\n",
        "  \n",
        "  def __init__(self, pretrained_model, n_classes):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.n_classes = n_classes\n",
        "    self.pretrained_model = pretrained_model\n",
        "    # Transposed convolutions (to upsampling previous layers)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.deconv1 = nn.ConvTranspose2d(512, 512, 3, 2, padding=1, dilation=1, output_padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(512)\n",
        "    self.deconv2 = nn.ConvTranspose2d(512, 256, 3, 2, padding=1, dilation=1, output_padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(256)\n",
        "    self.deconv3 = nn.ConvTranspose2d(256, 128, 3, 2, padding=1, dilation=1, output_padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.deconv4 = nn.ConvTranspose2d(128,  64, 3, 2, padding=1, dilation=1, output_padding=1)\n",
        "    self.bn4 = nn.BatchNorm2d(64)\n",
        "    self.deconv5 = nn.ConvTranspose2d( 64,  32, 3, 2, padding=1, dilation=1, output_padding=1)\n",
        "    self.bn5 = nn.BatchNorm2d(32)\n",
        "    # Convolutional score layer (replace the FCs layers)\n",
        "    self.score = nn.Conv2d(32, n_classes, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pretrained_model(x)\n",
        "    \n",
        "    # Skip connections (connect the output of one layer to a non-adjacent layer)\n",
        "    pool_5 = x['pool5']\n",
        "    pool_4 = x['pool4']\n",
        "    pool_3 = x['pool3']\n",
        "    \n",
        "    x = self.relu(self.deconv1(pool_5))\n",
        "    x = self.bn1(x+pool_4)\n",
        "    x = self.relu(self.deconv2(x))\n",
        "    x = self.bn2(x+pool_3)\n",
        "    x = self.bn3(self.relu(self.deconv3(x)))\n",
        "    x = self.bn4(self.relu(self.deconv4(x)))\n",
        "    x = self.bn5(self.relu(self.deconv5(x)))\n",
        "    x = self.score(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GIXHUw-EXV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ranges = {'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31))}\n",
        "cfg = {'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKrvrc91Kqnu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Test output sizes"
      ]
    },
    {
      "metadata": {
        "id": "Kqy4uauoHvBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "045f9b6c-1c50-4b54-edc2-04858cd7bd92"
      },
      "cell_type": "code",
      "source": [
        "batch_size, n_classes, h, w = 10, 20, 160, 160\n",
        "\n",
        "encoder = VGG16(cfg, ranges, requires_grad=True)\n",
        "decoder = FCN8s(encoder, n_classes)\n",
        "\n",
        "enc_input = torch.randn(batch_size, 3, 224, 224)\n",
        "dec_input = torch.randn(batch_size, 3, h, w)\n",
        "\n",
        "enc_output = encoder(enc_input)\n",
        "dec_output = decoder(dec_input)\n",
        "\n",
        "assert enc_output['pool5'].size() == torch.Size([batch_size, 512, 7, 7])\n",
        "assert dec_output.size() == torch.Size([batch_size, n_classes, h, w])\n",
        "print(\"Correct output sizes\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct output sizes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aScQ-FxCsdmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ]
    },
    {
      "metadata": {
        "id": "xDow_jB-shl5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test if the model works using a single batch"
      ]
    },
    {
      "metadata": {
        "id": "LHs13RXSn3S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "38908fea-2856-4953-c910-2bc4a528f89c"
      },
      "cell_type": "code",
      "source": [
        "fcn = FCN8s(VGG16(cfg,ranges), n_classes)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(fcn.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "x = torch.randn(batch_size, 3, h, w)\n",
        "y = torch.randn(batch_size, n_classes, h, w)\n",
        "y = torch.tensor(y, requires_grad=False)\n",
        "\n",
        "for i in range(10):\n",
        "  optimizer.zero_grad()\n",
        "  output = fcn(x)\n",
        "  output = torch.sigmoid(output)\n",
        "  loss = criterion(output, y)\n",
        "  loss.backward()\n",
        "  print(\"i: {}, loss: {:.5f}\".format(i, loss.item()))\n",
        "  optimizer.step()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i: 0, loss: 0.69971\n",
            "i: 1, loss: 0.69953\n",
            "i: 2, loss: 0.69921\n",
            "i: 3, loss: 0.69874\n",
            "i: 4, loss: 0.69814\n",
            "i: 5, loss: 0.69745\n",
            "i: 6, loss: 0.69664\n",
            "i: 7, loss: 0.69574\n",
            "i: 8, loss: 0.69475\n",
            "i: 9, loss: 0.69370\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}